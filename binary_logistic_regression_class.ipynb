{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import classification_report, confusion_matrix  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('C:\\\\Users\\\\fd299212\\\\Desktop\\\\lab_Stuff\\\\collaborations\\\\cady\\\\machineLearning\\\\lyme_data_gcfp.txt',sep='\\t')\n",
    "df = pd.read_csv('C:\\\\Users\\\\fd299212\\\\lyme_data_20220520.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in DF and fully populate with \"Neg\"\n",
    "#then alter to Pos for any 'Diag' column values that are not equal to \"Neg\" (various positive states)\n",
    "df['bin_diag'] = \"Neg\"\n",
    "df.loc[df['Diag']!=\"Neg\", 'bin_diag'] = \"Pos\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Diag'].value_counts()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5697c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X = df.drop(['Diag','ID'], axis=1)  \n",
    "#X = df.filter(['VlsE', 'DbpA', 'P58', 'OspC','ErpL','DbpB'],axis=1)  \n",
    "X = df.filter(['VlsE', 'DbpA', 'P58', 'OspC','ErpL','P66'],axis=1)  \n",
    "\n",
    "#Data Standardization gives the data zero mean and unit variance, it is considered good practice, \n",
    "#especially for algorithms such as KNN which is based on the distance of data points\n",
    "#however, there is some disagreement about it for logistic regression...may require testing for specific dataset results\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "X[0:5]\n",
    "y = df['bin_diag']\n",
    "#split original dataset into training and testing subsets\n",
    "#stratify=y ensures that the sampled sets attempt to represent each class's proportions as they were in the full set\n",
    "#the 'y' does not mean 'yes' it is the y vectors of class labels\n",
    "#note, random_state provides specific seed for pseudorandom generator to allow reproducible analysis of the model\n",
    "#remove this parameter to allow random selection each run\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#the hyperparameters being fed to the gridsearch in this case may include some that are not \n",
    "#applicable with each other. Invocations with those may raise warnings that should be able to be ignored\n",
    "#but to the degree practicable, feed compatible parameters together...\n",
    "\n",
    "#we define the set of parameter values that will be passed in as \"param_grid\"\n",
    "#max_iter is set very high due to non convergence errors that had been occurring. This can be revisited as data set \n",
    "#continues to grow\n",
    "param_grid = [{'C': [.1,1,2.5,5], 'penalty': ['none','l2'],'solver': ['lbfgs','newton-cg', 'sag'], 'max_iter':[8000]},             \n",
    "             {'C': [.1,1,2.5,5], 'penalty': ['none','l1','l2','elasticnet'],'solver': ['saga'], 'max_iter':[8000]},\n",
    "              {'C': [.1,1,2.5,5], 'penalty': ['l1','l2'],'solver': ['liblinear'], 'max_iter':[2000]}]\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "#this code implements the grid search\n",
    "grid = GridSearchCV(logreg,param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_estimator_.penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06039a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "print(grid.best_estimator_.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "#following lines are not needed as gridsearchCV does 'refit' (retrains best estimator on full set provided[the whole\n",
    "#training set in this case]) by default\n",
    "#model.set_params(max_iter=5000)\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "print('Predicted Classes:')\n",
    "print(yhat)\n",
    "print('Actual Classes:')\n",
    "print(y_test)\n",
    "\n",
    "score = model.score(X_test,y_test)\n",
    "# report the model performance\n",
    "print('Accuracy: %.3f ' % (score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f36849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities with a multinomial logistic regression model\n",
    "from sklearn.datasets import make_classification\n",
    "# predict a multinomial probability distribution\n",
    "yprobs = model.predict_proba(X_test)\n",
    "# summarize the predicted probabilities\n",
    "print('Predicted Probabilities:')\n",
    "print(yprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following is test code to output the probabilities in an easy to \n",
    "#read format using the dataframe display and format options\n",
    "import pandas as pd\n",
    "def plot_probabilities(prob_array, col_labels, sample_indices):\n",
    "    if yprobs.shape[1] == len(classes):\n",
    "        prob_df = pd.DataFrame(prob_array, columns=col_labels)\n",
    "        prob_df['original sample index'] = sample_indices\n",
    "        pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "        pd.set_option('display.precision', 3)\n",
    "        display(prob_df)\n",
    "    else:\n",
    "        print('Incorrect label list length')\n",
    "        \n",
    "classes = ['Negative','Positive']   \n",
    "rows = y_test.index\n",
    "print(\"Probabilities:\")\n",
    "plot_probabilities(yprobs , classes, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "#code from https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test, yhat)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_test, yhat))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Negative','Pos'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff3d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
